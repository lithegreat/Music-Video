{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install -U git+https://github.com/facebookresearch/audiocraft#egg=audiocraft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lyric generation \n",
    "Right now is done with Llama Model by using the following prompts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_host = 'http://80.158.2.104:11434'\n",
    "from ollama import Client\n",
    "ollama_client = Client(host=ollama_host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from together import Together\n",
    "\n",
    "os.environ['TOGETHER_API_KEY'] =  \"8069bcddb5b335ea3e2f23e9d58d83d5dfb270ee6ffcb8a546fbcdf8fb336dac\"\n",
    "\n",
    "together_client = Together(api_key=os.environ.get(\"TOGETHER_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_llama_3_8b_TOGETHER_API(system_intel, prompt):\n",
    "\n",
    "    chat_completion_response = together_client.chat.completions.create(\n",
    "        messages=[{\"role\": \"system\",\n",
    "                   \"content\": system_intel},\n",
    "                  {\"role\": \"user\", \"content\": prompt}],\n",
    "        model=\"meta-llama/Llama-3-8b-chat-hf\",\n",
    "    )\n",
    "    response_message = chat_completion_response.choices[0].message.content\n",
    "\n",
    "    return response_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from together import Together\n",
    "\n",
    "os.environ['TOGETHER_API_KEY'] =  \"8069bcddb5b335ea3e2f23e9d58d83d5dfb270ee6ffcb8a546fbcdf8fb336dac\"\n",
    "\n",
    "together_client = Together(api_key=os.environ.get(\"TOGETHER_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_intel = \"You are one of the best song writers in the world.\\nKnowledge cutoff: 2021-09-01\\nCurrent date: 2023-03-02\"\n",
    "#ToDo add examples to the prompt \n",
    "prompt = \"\"\"Write a set of compelling lyrics for a song and perform it with your exceptional singing skills. The lyrics should \n",
    "convey a meaningful message or tell a captivating story, and your performance should showcase your vocal abilities and emotional expression. \n",
    "Your goal is to create an original and engaging musical piece that resonates with the audience. Feel free to explore various themes and musical styles \n",
    "to demonstrate the depth of your talent as a lyricist and singer.\n",
    "\"\"\"\n",
    "lyrics = ask_llama_3_8b_stream_TOGETHER_API(system_intel, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_prompt = \"Use this chorus to descriptive the possible background music that would fit it\" + lyrics\n",
    "instructions = ask_llama_3_8b_stream_TOGETHER_API(system_intel, lyrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bring in the libraries \n",
    "from audiocraft.models import musicgen\n",
    "from audiocraft.utils.notebook import display_audio\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bring in the model this will automatically download the weights \n",
    "class musicModel: \n",
    "    def __init__(self, model_type: str, audio_length) -> Audio:\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.model = musicgen.MusicGen.get_pretrained(model_type, device=self.device)\n",
    "        self.audio_length = audio_length\n",
    "        self.__set_audio_length()\n",
    "    \n",
    "    def __set_audio_length(self):\n",
    "        self.model.set_generation_params(duration=self.audio_length)\n",
    "    def generateAudio(self, instructions): \n",
    "        res = self.model.generate([\n",
    "            instructions\n",
    "        ], \n",
    "            progress=True)\n",
    "        self.__display_audio(res)\n",
    "    def __display_audio(audio): \n",
    "        display_audio(audio, 32000)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voice generation \n",
    "Reference model for voice generation: https://huggingface.co/coqui/XTTS-v2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
