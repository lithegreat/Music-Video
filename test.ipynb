{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting audiocraft"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\980012754\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\980012754\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/audiocraft 'C:\\Users\\980012754\\AppData\\Local\\Temp\\pip-install-o_6tbkj_\\audiocraft_5f8078b0da164d2982929d3ffd2d048e'\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\980012754\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\980012754\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\980012754\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\980012754\\appdata\\roaming\\python\\python310\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Cloning https://github.com/facebookresearch/audiocraft to c:\\users\\980012754\\appdata\\local\\temp\\pip-install-o_6tbkj_\\audiocraft_5f8078b0da164d2982929d3ffd2d048e\n",
      "  Resolved https://github.com/facebookresearch/audiocraft to commit adf0b04a4452f171970028fcf80f101dd5e26e19\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: av==11.0.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from audiocraft) (11.0.0)\n",
      "Requirement already satisfied: einops in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from audiocraft) (0.8.0)\n",
      "Requirement already satisfied: flashy>=0.0.1 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from audiocraft) (0.0.2)\n",
      "Requirement already satisfied: hydra-core>=1.1 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from audiocraft) (1.3.2)\n",
      "Requirement already satisfied: hydra_colorlog in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from audiocraft) (1.2.0)\n",
      "Requirement already satisfied: julius in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from audiocraft) (0.2.7)\n",
      "Requirement already satisfied: num2words in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from audiocraft) (0.5.13)\n",
      "Requirement already satisfied: numpy<2.0.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from audiocraft) (1.26.4)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from audiocraft) (0.2.0)\n",
      "Requirement already satisfied: spacy>=3.6.1 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from audiocraft) (3.7.5)\n",
      "Requirement already satisfied: torch==2.1.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from audiocraft) (2.1.0)\n",
      "Requirement already satisfied: torchaudio<2.1.2,>=2.0.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from audiocraft) (2.1.0)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from audiocraft) (0.23.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from audiocraft) (4.66.4)\n",
      "Requirement already satisfied: transformers>=4.31.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from audiocraft) (4.41.2)\n",
      "Requirement already satisfied: xformers<0.0.23 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from audiocraft) (0.0.22.post7)\n",
      "Requirement already satisfied: demucs in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from audiocraft) (4.0.1)\n",
      "Requirement already satisfied: librosa in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from audiocraft) (0.10.2.post1)\n",
      "Requirement already satisfied: soundfile in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from audiocraft) (0.12.1)\n",
      "Requirement already satisfied: gradio in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from audiocraft) (4.36.1)\n",
      "Requirement already satisfied: torchmetrics in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from audiocraft) (1.4.0.post0)\n",
      "Requirement already satisfied: encodec in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from audiocraft) (0.1.1)\n",
      "Requirement already satisfied: protobuf in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from audiocraft) (5.27.1)\n",
      "Requirement already satisfied: torchvision==0.16.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from audiocraft) (0.16.0)\n",
      "Requirement already satisfied: torchtext==0.16.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from audiocraft) (0.16.0)\n",
      "Requirement already satisfied: pesq in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from audiocraft) (0.0.4)\n",
      "Requirement already satisfied: pystoi in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from audiocraft) (0.4.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from torch==2.1.0->audiocraft) (3.15.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from torch==2.1.0->audiocraft) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from torch==2.1.0->audiocraft) (1.12.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from torch==2.1.0->audiocraft) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from torch==2.1.0->audiocraft) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from torch==2.1.0->audiocraft) (2024.6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from torchtext==0.16.0->audiocraft) (2.32.3)\n",
      "Requirement already satisfied: torchdata==0.7.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from torchtext==0.16.0->audiocraft) (0.7.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from torchvision==0.16.0->audiocraft) (10.3.0)\n",
      "Requirement already satisfied: urllib3>=1.25 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from torchdata==0.7.0->torchtext==0.16.0->audiocraft) (2.2.2)\n",
      "Requirement already satisfied: dora-search in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from flashy>=0.0.1->audiocraft) (0.1.12)\n",
      "Requirement already satisfied: colorlog in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from flashy>=0.0.1->audiocraft) (6.8.2)\n",
      "Requirement already satisfied: omegaconf<2.4,>=2.2 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from hydra-core>=1.1->audiocraft) (2.3.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from hydra-core>=1.1->audiocraft) (4.9.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from hydra-core>=1.1->audiocraft) (24.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from spacy>=3.6.1->audiocraft) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from spacy>=3.6.1->audiocraft) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from spacy>=3.6.1->audiocraft) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from spacy>=3.6.1->audiocraft) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from spacy>=3.6.1->audiocraft) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from spacy>=3.6.1->audiocraft) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from spacy>=3.6.1->audiocraft) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from spacy>=3.6.1->audiocraft) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from spacy>=3.6.1->audiocraft) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from spacy>=3.6.1->audiocraft) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from spacy>=3.6.1->audiocraft) (0.12.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from spacy>=3.6.1->audiocraft) (2.7.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from spacy>=3.6.1->audiocraft) (69.5.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from spacy>=3.6.1->audiocraft) (3.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from tqdm->audiocraft) (0.4.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from transformers>=4.31.0->audiocraft) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from transformers>=4.31.0->audiocraft) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from transformers>=4.31.0->audiocraft) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from transformers>=4.31.0->audiocraft) (0.4.3)\n",
      "Requirement already satisfied: lameenc>=1.2 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from demucs->audiocraft) (1.7.0)\n",
      "Requirement already satisfied: openunmix in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from demucs->audiocraft) (1.3.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from gradio->audiocraft) (23.2.1)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from gradio->audiocraft) (5.3.0)\n",
      "Requirement already satisfied: fastapi in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from gradio->audiocraft) (0.111.0)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from gradio->audiocraft) (0.3.2)\n",
      "Requirement already satisfied: gradio-client==1.0.1 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from gradio->audiocraft) (1.0.1)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from gradio->audiocraft) (0.27.0)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from gradio->audiocraft) (6.4.0)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from gradio->audiocraft) (2.1.5)\n",
      "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from gradio->audiocraft) (3.9.0)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from gradio->audiocraft) (3.10.5)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from gradio->audiocraft) (2.2.2)\n",
      "Requirement already satisfied: pydub in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from gradio->audiocraft) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from gradio->audiocraft) (0.0.9)\n",
      "Requirement already satisfied: ruff>=0.2.2 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from gradio->audiocraft) (0.4.10)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from gradio->audiocraft) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from gradio->audiocraft) (0.12.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from gradio->audiocraft) (0.30.1)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from gradio-client==1.0.1->gradio->audiocraft) (11.0.3)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from librosa->audiocraft) (3.0.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from librosa->audiocraft) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from librosa->audiocraft) (1.5.0)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from librosa->audiocraft) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from librosa->audiocraft) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from librosa->audiocraft) (0.60.0)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from librosa->audiocraft) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from librosa->audiocraft) (0.3.7)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from librosa->audiocraft) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from librosa->audiocraft) (1.0.8)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from soundfile->audiocraft) (1.16.0)\n",
      "Requirement already satisfied: docopt>=0.6.2 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from num2words->audiocraft) (0.6.2)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from torchmetrics->audiocraft) (0.11.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio->audiocraft) (4.22.0)\n",
      "Requirement already satisfied: toolz in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio->audiocraft) (0.12.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from cffi>=1.0->soundfile->audiocraft) (2.22)\n",
      "Requirement already satisfied: anyio in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from httpx>=0.24.1->gradio->audiocraft) (4.4.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from httpx>=0.24.1->gradio->audiocraft) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from httpx>=0.24.1->gradio->audiocraft) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from httpx>=0.24.1->gradio->audiocraft) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from httpx>=0.24.1->gradio->audiocraft) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio->audiocraft) (0.14.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3.6.1->audiocraft) (1.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from matplotlib~=3.0->gradio->audiocraft) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from matplotlib~=3.0->gradio->audiocraft) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from matplotlib~=3.0->gradio->audiocraft) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from matplotlib~=3.0->gradio->audiocraft) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from matplotlib~=3.0->gradio->audiocraft) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from matplotlib~=3.0->gradio->audiocraft) (2.9.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from numba>=0.51.0->librosa->audiocraft) (0.43.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from pandas<3.0,>=1.0->gradio->audiocraft) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from pandas<3.0,>=1.0->gradio->audiocraft) (2024.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from pooch>=1.1->librosa->audiocraft) (4.2.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.6.1->audiocraft) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.6.1->audiocraft) (2.18.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from requests->torchtext==0.16.0->audiocraft) (3.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from scikit-learn>=0.20.0->librosa->audiocraft) (3.5.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy>=3.6.1->audiocraft) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy>=3.6.1->audiocraft) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy>=3.6.1->audiocraft) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy>=3.6.1->audiocraft) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy>=3.6.1->audiocraft) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.6.1->audiocraft) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.6.1->audiocraft) (7.0.4)\n",
      "Requirement already satisfied: retrying in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from dora-search->flashy>=0.0.1->audiocraft) (1.3.4)\n",
      "Requirement already satisfied: submitit in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from dora-search->flashy>=0.0.1->audiocraft) (1.5.1)\n",
      "Requirement already satisfied: treetable in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from dora-search->flashy>=0.0.1->audiocraft) (0.2.5)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from fastapi->gradio->audiocraft) (0.37.2)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.2 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from fastapi->gradio->audiocraft) (0.0.4)\n",
      "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from fastapi->gradio->audiocraft) (5.10.0)\n",
      "Requirement already satisfied: email_validator>=2.0.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from fastapi->gradio->audiocraft) (2.2.0)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from sympy->torch==2.1.0->audiocraft) (1.3.0)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from email_validator>=2.0.0->fastapi->gradio->audiocraft) (2.6.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->audiocraft) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->audiocraft) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->audiocraft) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->audiocraft) (0.18.1)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3.6.1->audiocraft) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio->audiocraft) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.6.1->audiocraft) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.6.1->audiocraft) (2.18.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=3.6.1->audiocraft) (1.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from anyio->httpx>=0.24.1->gradio->audiocraft) (1.2.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from uvicorn[standard]>=0.12.0->fastapi->gradio->audiocraft) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from uvicorn[standard]>=0.12.0->fastapi->gradio->audiocraft) (1.0.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from uvicorn[standard]>=0.12.0->fastapi->gradio->audiocraft) (0.22.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.1 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from submitit->dora-search->flashy>=0.0.1->audiocraft) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\980012754\\documents\\tum_8_semester\\nlp_projekt_woche\\deeplearningdudes_music_video\\.conda\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.6.1->audiocraft) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U git+https://github.com/facebookresearch/audiocraft#egg=audiocraft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lyric generation \n",
    "Right now is done with Llama Model by using the following prompts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_host = 'http://80.158.2.104:11434'\n",
    "from ollama import Client\n",
    "ollama_client = Client(host=ollama_host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from together import Together\n",
    "\n",
    "os.environ['TOGETHER_API_KEY'] =  \"8069bcddb5b335ea3e2f23e9d58d83d5dfb270ee6ffcb8a546fbcdf8fb336dac\"\n",
    "\n",
    "together_client = Together(api_key=os.environ.get(\"TOGETHER_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_llama_3_8b_TOGETHER_API(system_intel, prompt):\n",
    "\n",
    "    chat_completion_response = together_client.chat.completions.create(\n",
    "        messages=[{\"role\": \"system\",\n",
    "                   \"content\": system_intel},\n",
    "                  {\"role\": \"user\", \"content\": prompt}],\n",
    "        model=\"meta-llama/Llama-3-8b-chat-hf\",\n",
    "    )\n",
    "    response_message = chat_completion_response.choices[0].message.content\n",
    "\n",
    "    return response_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_intel = \"You are one of the best song writers in the world.\\nKnowledge cutoff: 2021-09-01\\nCurrent date: 2023-03-02\"\n",
    "#ToDo add examples to the prompt \n",
    "topic = \"I met my ex on Tik-Tok\"\n",
    "prompt = f\"\"\"Create a set of song lyrics of the topic {topic} that demonstrate your vocal abilities and emotional expression. \n",
    "The lyrics should be accompanied by a professional-level audio recording with clear enunciation and crystal-clear audio quality. \n",
    "The song should feature a captivating melody and sophisticated arrangement, production, and performance. \n",
    "The lyrics must rhyme to enhance the song's flow and aesthetic appeal. You are encouraged to explore various themes and musical styles, \n",
    "but the final composition must meet the above criteria to showcase your talent and depth as a creator and performer. \n",
    "The lyrics should convey emotional expression and physical actions to ensure a high-quality performance.\n",
    "\"\"\"\n",
    "lyrics = ask_llama_3_8b_TOGETHER_API(system_intel, prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Song Title:** \"Swipe Right on Memories\"\n",
      "\n",
      "**Genre:** Pop-Rock with a hint of Electronic elements\n",
      "\n",
      "**Tempo:** Moderate (around 120 BPM)\n",
      "\n",
      "**Time Signature:** 4/4\n",
      "\n",
      "**Key:** C Major\n",
      "\n",
      "**Lyrics:**\n",
      "\n",
      "Verse 1:\n",
      "I was scrolling through my feed, feeling so alone\n",
      "When I saw your face, and my heart started to moan\n",
      "A swipe right, and our stories aligned\n",
      "Little did I know, our love would be redefined\n",
      "\n",
      "Chorus:\n",
      "I met my ex on Tik-Tok, in a world of endless fame\n",
      "We danced to the rhythm, of our own little game\n",
      "We laughed, we loved, we lived, in a virtual haze\n",
      "But now I'm left with just a memory, and a fading phase\n",
      "\n",
      "Verse 2:\n",
      "We'd lip-sync to our favorite songs, and our hearts would beat as one\n",
      "We'd create our own stories, and our love would be won\n",
      "But like a fleeting dream, our love would fade away\n",
      "Leaving me with just a memory, of our digital day\n",
      "\n",
      "Chorus:\n",
      "I met my ex on Tik-Tok, in a world of endless fame\n",
      "We danced to the rhythm, of our own little game\n",
      "We laughed, we loved, we lived, in a virtual haze\n",
      "But now I'm left with just a memory, and a fading phase\n",
      "\n",
      "Bridge:\n",
      "We'd take a screenshot, of our love so true\n",
      "But like a ghost, our love would disappear from view\n",
      "I'm left with just a memory, of our digital past\n",
      "Wondering if our love will ever truly last\n",
      "\n",
      "Chorus:\n",
      "I met my ex on Tik-Tok, in a world of endless fame\n",
      "We danced to the rhythm, of our own little game\n",
      "We laughed, we loved, we lived, in a virtual haze\n",
      "But now I'm left with just a memory, and a fading phase\n",
      "\n",
      "**Audio Recording:**\n",
      "\n",
      "The song features a mix of acoustic and electronic elements, with a focus on showcasing the vocalist's range and emotional expression. The arrangement is designed to build tension and release, with a focus on the chorus and bridge.\n",
      "\n",
      "* The verse features a simple, pulsing electronic beat, accompanied by a minimalist piano melody and subtle ambient pads.\n",
      "* The chorus introduces a driving rock rhythm, with crunching guitars and a soaring vocal performance.\n",
      "* The bridge features a haunting piano solo, accompanied by atmospheric synths and a subtle drum machine pattern.\n",
      "* The final chorus features a reprise of the rock rhythm, with added layers of harmonies and a dramatic build-up to the song's conclusion.\n",
      "\n",
      "**Vocal Performance:**\n",
      "\n",
      "The vocalist delivers a powerful, emotive performance, with a focus on conveying the emotional depth of the lyrics. The vocal range is showcased throughout the song, with a focus on the chorus and bridge.\n",
      "\n",
      "* The verse features a more subdued, introspective performance, with a focus on storytelling and emotional expression.\n",
      "* The chorus features a more dramatic, anthemic performance, with a focus on showcasing the vocalist's range and power.\n",
      "* The bridge features a more intimate, vulnerable performance, with a focus on conveying the emotional pain and longing.\n",
      "\n",
      "**Production and Performance:**\n",
      "\n",
      "The production is designed to be polished and professional, with a focus on showcasing the vocalist's performance and the song's emotional depth. The arrangement is carefully crafted to build tension and release, with a focus on the chorus and bridge.\n",
      "\n",
      "* The mix is balanced and clear, with a focus on the vocalist's performance and the song's emotional impact.\n",
      "* The mastering is designed to be loud and clear, with a focus on delivering a high-quality listening experience.\n",
      "\n",
      "**Physical Actions:**\n",
      "\n",
      "The performance features a range of physical actions, designed to enhance the emotional expression and storytelling of the lyrics.\n",
      "\n",
      "* The vocalist performs a range of gestures and movements, including hand gestures, facial expressions, and body language.\n",
      "* The performance features a range of props and visual elements, including screens, lights, and projections.\n",
      "* The choreography is designed to be dynamic and engaging, with a focus on conveying the emotional depth and complexity of the lyrics.\n",
      "\n",
      "**Overall:**\n",
      "\n",
      "\"Swipe Right on Memories\" is a powerful, emotive song that showcases the vocalist's range and emotional expression. The arrangement is carefully crafted to build tension and release, with a focus on the chorus and bridge. The production is polished and professional, with a focus on delivering a high-quality listening experience. The physical actions and performance are designed to enhance the emotional expression and storytelling of the lyrics, making this a standout track in any genre.\n"
     ]
    }
   ],
   "source": [
    "print(lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asked chatGPT for help this is the input prompt: Give me a prompt to transform the following lyrics into musical instructions for a music ai model to produce the background music for this lyrics\n",
    "instruction_prompt = \"Lyrics: \"  + lyrics +  \"\"\"Instructions:\n",
    "    Genre and Style:\n",
    "    Choose a genre that complements the mood and message of the lyrics. For example, if the lyrics are about love and emotion, a pop or ballad style would be appropriate. If they are energetic and motivational, consider a rock or electronic genre.\n",
    "    Tempo:\n",
    "    Set the tempo to match the pacing of the lyrics. For example, a moderate tempo (around 90-110 BPM) for a relaxed and reflective feel, or a faster tempo (120-140 BPM) for energetic and upbeat lyrics.\n",
    "    Key and Harmony:\n",
    "    Determine the key that fits the emotional tone of the lyrics. Major keys for a happy and uplifting feel, minor keys for a more somber and introspective mood.\n",
    "    Include chord progressions that support the lyrical content. Common progressions like I-IV-V-I for a traditional feel or ii-V-I for a jazzier vibe.\n",
    "    Instrumentation:\n",
    "    Suggest the instruments to be used. For example, acoustic guitar and piano for a more intimate setting, electric guitar and drums for rock, or synthesizers for electronic music.\n",
    "    Arrangement:\n",
    "    Outline the structure of the song. Include sections like intro, verse, chorus, bridge, and outro, specifying any changes in instrumentation or dynamics.\n",
    "    Indicate where the lyrics should be emphasized, perhaps through a build-up in the music or a change in instrumentation.\n",
    "    Mood and Dynamics:\n",
    "    Describe the overall mood and any dynamic changes throughout the song. For instance, start softly and build up to a powerful chorus, then bring it down for a more introspective bridge.\n",
    "    Production Effects:\n",
    "    Recommend any production effects that could enhance the music. Reverb and delay for a spacious feel, distortion for intensity, or clean production for a polished sound.\n",
    "\"\"\"\n",
    "instructions = ask_llama_3_8b_TOGETHER_API(system_intel, instruction_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What a beautiful song! I can already imagine the emotional resonance it would evoke in the audience. Here's my take on the genre, style, tempo, key, harmony, instrumentation, arrangement, mood, and dynamics:\n",
      "\n",
      "**Genre and Style:** Indie-Folk/Pop\n",
      "\n",
      "The lyrics have a introspective and emotional quality that lends itself well to an indie-folk/pop genre. The song's focus on storytelling, poetic lyrics, and soaring melodies makes it a great fit for this style.\n",
      "\n",
      "**Tempo:** Moderate (around 90-110 BPM)\n",
      "\n",
      "The tempo is moderate, allowing for a sense of introspection and contemplation. This pace also allows for a build-up in the chorus and a sense of release.\n",
      "\n",
      "**Key and Harmony:** Minor key (e.g., A minor or E minor)\n",
      "\n",
      "The minor key creates a somber and introspective mood, fitting for a song about longing and nostalgia. The harmony could feature a mix of minor and major chords to create a sense of tension and resolution.\n",
      "\n",
      "**Chord Progression:** I-IV-V-I (or ii-V-I for a jazzier vibe)\n",
      "\n",
      "The I-IV-V-I progression is a classic and timeless choice, while the ii-V-I progression adds a touch of sophistication and complexity.\n",
      "\n",
      "**Instrumentation:**\n",
      "\n",
      "* Piano: A grand piano or a soft, intimate piano sound would be perfect for this song.\n",
      "* Acoustic Guitar: A softly played acoustic guitar adds warmth and texture to the song.\n",
      "* Strings: A minimalist arrangement of violins and cellos would add a touch of melancholy and longing.\n",
      "* Percussion: A gentle, pulsing rhythm on the drums or a soft, mallet-driven percussion would underscore the emotional intensity of the song.\n",
      "\n",
      "**Arrangement:**\n",
      "\n",
      "* Intro: A soft, piano-driven intro sets the mood and establishes the key.\n",
      "* Verse 1: The acoustic guitar joins, adding warmth and texture.\n",
      "* Chorus: The strings and percussion enter, building up the emotional intensity.\n",
      "* Verse 2: The arrangement remains similar to Verse 1, with the addition of some subtle string textures.\n",
      "* Chorus: The same arrangement as the first chorus, with a slight build-up in intensity.\n",
      "* Bridge: A minimalist arrangement, focusing on the piano and a soft, mallet-driven percussion.\n",
      "* Chorus: A final, soaring chorus with the full arrangement.\n",
      "\n",
      "**Mood and Dynamics:**\n",
      "\n",
      "* The song starts softly and builds up to a more intense, emotional climax.\n",
      "* The bridge is a moment of vulnerability, with a focus on the piano and a soft, mallet-driven percussion.\n",
      "* The final chorus is a powerful, emotional release, with the full arrangement.\n",
      "\n",
      "**Production Effects:**\n",
      "\n",
      "* Reverb and delay: Add a sense of space and depth to the piano and strings.\n",
      "* Distortion: Add a touch of intensity to the guitar and percussion.\n",
      "* Clean production: Ensure a polished, professional sound.\n",
      "\n",
      "Overall, \"Echoes in the Dark\" is a beautiful, emotional song that would resonate with audiences. The indie-folk/pop genre, moderate tempo, and minor key create a somber and introspective mood, while the chord progression, instrumentation, and arrangement build up to a powerful, emotional climax.\n"
     ]
    }
   ],
   "source": [
    "print(instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.1.0+cu121 with CUDA 1201 (you have 2.1.0+cpu)\n",
      "    Python  3.10.11 (you have 3.10.14)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n",
      "c:\\Users\\980012754\\Documents\\TUM_8_SEMESTER\\NLP_Projekt_Woche\\DeepLearningDudes_Music_Video\\.conda\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "#Bring in the libraries \n",
    "from audiocraft.models import musicgen\n",
    "from audiocraft.utils.notebook import display_audio\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bring in the model this will automatically download the weights \n",
    "class musicModel: \n",
    "    def __init__(self, model_type: str, audio_length):\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.model = musicgen.MusicGen.get_pretrained(model_type, device=self.device)\n",
    "        self.audio_length = audio_length\n",
    "        self.__set_audio_length()\n",
    "    \n",
    "    def __set_audio_length(self):\n",
    "        self.model.set_generation_params(duration=self.audio_length)\n",
    "    def generateAudio(self, instructions): \n",
    "        res = self.model.generate([\n",
    "            instructions\n",
    "        ], \n",
    "            progress=True)\n",
    "        self.__display_audio(res)\n",
    "    def __display_audio(audio): \n",
    "        display_audio(audio, 32000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\980012754\\Documents\\TUM_8_SEMESTER\\NLP_Projekt_Woche\\DeepLearningDudes_Music_Video\\.conda\\lib\\site-packages\\audiocraft\\models\\musicgen.py:80: UserWarning: MusicGen pretrained model relying on deprecated checkpoint mapping. Please use full pre-trained id instead: facebook/musicgen-small\n",
      "  warnings.warn(\n",
      "c:\\Users\\980012754\\Documents\\TUM_8_SEMESTER\\NLP_Projekt_Woche\\DeepLearningDudes_Music_Video\\.conda\\lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1806 /    903\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m modelMusic \u001b[38;5;241m=\u001b[39m musicModel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmall\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m90\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodelMusic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerateAudio\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 12\u001b[0m, in \u001b[0;36mmusicModel.generateAudio\u001b[1;34m(self, instructions)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerateAudio\u001b[39m(\u001b[38;5;28mself\u001b[39m, instructions): \n\u001b[1;32m---> 12\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43minstructions\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__display_audio(res)\n",
      "File \u001b[1;32mc:\\Users\\980012754\\Documents\\TUM_8_SEMESTER\\NLP_Projekt_Woche\\DeepLearningDudes_Music_Video\\.conda\\lib\\site-packages\\audiocraft\\models\\genmodel.py:161\u001b[0m, in \u001b[0;36mBaseGenModel.generate\u001b[1;34m(self, descriptions, progress, return_tokens)\u001b[0m\n\u001b[0;32m    159\u001b[0m attributes, prompt_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_tokens_and_attributes(descriptions, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m prompt_tokens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 161\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattributes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_tokens:\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_audio(tokens), tokens\n",
      "File \u001b[1;32mc:\\Users\\980012754\\Documents\\TUM_8_SEMESTER\\NLP_Projekt_Woche\\DeepLearningDudes_Music_Video\\.conda\\lib\\site-packages\\audiocraft\\models\\musicgen.py:296\u001b[0m, in \u001b[0;36mMusicGen._generate_tokens\u001b[1;34m(self, attributes, prompt_tokens, progress)\u001b[0m\n\u001b[0;32m    290\u001b[0m     attr\u001b[38;5;241m.\u001b[39mwav[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mself_wav\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m WavCondition(\n\u001b[0;32m    291\u001b[0m         ref_wav[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, positions \u001b[38;5;241m%\u001b[39m wav_length],\n\u001b[0;32m    292\u001b[0m         torch\u001b[38;5;241m.\u001b[39mfull_like(ref_wav[\u001b[38;5;241m1\u001b[39m], wav_target_length),\n\u001b[0;32m    293\u001b[0m         [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_rate] \u001b[38;5;241m*\u001b[39m ref_wav[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m    294\u001b[0m         [\u001b[38;5;28;01mNone\u001b[39;00m], [\u001b[38;5;241m0.\u001b[39m])\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautocast:\n\u001b[1;32m--> 296\u001b[0m     gen_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m    297\u001b[0m         prompt_tokens, attributes,\n\u001b[0;32m    298\u001b[0m         callback\u001b[38;5;241m=\u001b[39mcallback, max_gen_len\u001b[38;5;241m=\u001b[39mmax_gen_len, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_params)\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompt_tokens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    300\u001b[0m     all_tokens\u001b[38;5;241m.\u001b[39mappend(gen_tokens)\n",
      "File \u001b[1;32mc:\\Users\\980012754\\Documents\\TUM_8_SEMESTER\\NLP_Projekt_Woche\\DeepLearningDudes_Music_Video\\.conda\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\980012754\\Documents\\TUM_8_SEMESTER\\NLP_Projekt_Woche\\DeepLearningDudes_Music_Video\\.conda\\lib\\site-packages\\audiocraft\\models\\lm.py:510\u001b[0m, in \u001b[0;36mLMModel.generate\u001b[1;34m(self, prompt, conditions, num_samples, max_gen_len, use_sampling, temp, top_k, top_p, cfg_coef, two_step_cfg, remove_prompts, check, callback, **kwargs)\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (curr_sequence \u001b[38;5;241m==\u001b[39m unknown_token)\u001b[38;5;241m.\u001b[39many()\n\u001b[0;32m    509\u001b[0m \u001b[38;5;66;03m# sample next token from the model, next token shape is [B, K, 1]\u001b[39;00m\n\u001b[1;32m--> 510\u001b[0m next_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample_next_token\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcurr_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg_conditions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munconditional_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_sampling\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcfg_coef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg_coef\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtwo_step_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtwo_step_cfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;66;03m# ensure the tokens that should be masked are properly set to special_token_id\u001b[39;00m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;66;03m# as the model never output special_token_id\u001b[39;00m\n\u001b[0;32m    515\u001b[0m valid_mask \u001b[38;5;241m=\u001b[39m mask[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, offset:offset\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mexpand(B, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\980012754\\Documents\\TUM_8_SEMESTER\\NLP_Projekt_Woche\\DeepLearningDudes_Music_Video\\.conda\\lib\\site-packages\\audiocraft\\models\\lm.py:369\u001b[0m, in \u001b[0;36mLMModel._sample_next_token\u001b[1;34m(self, sequence, cfg_conditions, unconditional_state, use_sampling, temp, top_k, top_p, cfg_coef, two_step_cfg)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m condition_tensors:\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;66;03m# Preparing for CFG, predicting both conditional and unconditional logits.\u001b[39;00m\n\u001b[0;32m    368\u001b[0m     sequence \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([sequence, sequence], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 369\u001b[0m all_logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[43m    \u001b[49m\u001b[43msequence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconditions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcondition_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcondition_tensors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m condition_tensors:\n\u001b[0;32m    373\u001b[0m     cond_logits, uncond_logits \u001b[38;5;241m=\u001b[39m all_logits\u001b[38;5;241m.\u001b[39msplit(B, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# [B, K, T, card]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\980012754\\Documents\\TUM_8_SEMESTER\\NLP_Projekt_Woche\\DeepLearningDudes_Music_Video\\.conda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\980012754\\Documents\\TUM_8_SEMESTER\\NLP_Projekt_Woche\\DeepLearningDudes_Music_Video\\.conda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\980012754\\Documents\\TUM_8_SEMESTER\\NLP_Projekt_Woche\\DeepLearningDudes_Music_Video\\.conda\\lib\\site-packages\\audiocraft\\models\\lm.py:257\u001b[0m, in \u001b[0;36mLMModel.forward\u001b[1;34m(self, sequence, conditions, condition_tensors, stage)\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conditions, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pass both conditions and condition_tensors.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    255\u001b[0m input_, cross_attention_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuser(input_, condition_tensors)\n\u001b[1;32m--> 257\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcross_attention_src\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attention_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m                       \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn_mask_per_stage\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstage\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_norm:\n\u001b[0;32m    260\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_norm(out)\n",
      "File \u001b[1;32mc:\\Users\\980012754\\Documents\\TUM_8_SEMESTER\\NLP_Projekt_Woche\\DeepLearningDudes_Music_Video\\.conda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\980012754\\Documents\\TUM_8_SEMESTER\\NLP_Projekt_Woche\\DeepLearningDudes_Music_Video\\.conda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\980012754\\Documents\\TUM_8_SEMESTER\\NLP_Projekt_Woche\\DeepLearningDudes_Music_Video\\.conda\\lib\\site-packages\\audiocraft\\modules\\transformer.py:708\u001b[0m, in \u001b[0;36mStreamingTransformer.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    705\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositional_scale \u001b[38;5;241m*\u001b[39m pos_emb\n\u001b[0;32m    707\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m--> 708\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_layer(layer, x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_streaming:\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_streaming_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moffsets\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m offsets \u001b[38;5;241m+\u001b[39m T\n",
      "File \u001b[1;32mc:\\Users\\980012754\\Documents\\TUM_8_SEMESTER\\NLP_Projekt_Woche\\DeepLearningDudes_Music_Video\\.conda\\lib\\site-packages\\audiocraft\\modules\\transformer.py:665\u001b[0m, in \u001b[0;36mStreamingTransformer._apply_layer\u001b[1;34m(self, layer, *args, **kwargs)\u001b[0m\n\u001b[0;32m    663\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpointing\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 665\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    667\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch_checkpoint(layer, \u001b[38;5;241m*\u001b[39margs, use_reentrant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\980012754\\Documents\\TUM_8_SEMESTER\\NLP_Projekt_Woche\\DeepLearningDudes_Music_Video\\.conda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\980012754\\Documents\\TUM_8_SEMESTER\\NLP_Projekt_Woche\\DeepLearningDudes_Music_Video\\.conda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\980012754\\Documents\\TUM_8_SEMESTER\\NLP_Projekt_Woche\\DeepLearningDudes_Music_Video\\.conda\\lib\\site-packages\\audiocraft\\modules\\transformer.py:563\u001b[0m, in \u001b[0;36mStreamingTransformerLayer.forward\u001b[1;34m(self, src, src_mask, src_key_padding_mask, cross_attention_src)\u001b[0m\n\u001b[0;32m    559\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_scale_1(\n\u001b[0;32m    560\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sa_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x), src_mask, src_key_padding_mask))\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cross_attention_src \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    562\u001b[0m         x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_scale_cross(\n\u001b[1;32m--> 563\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cross_attention_block\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_cross\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcross_attention_src\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    565\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_scale_2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x)))\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\980012754\\Documents\\TUM_8_SEMESTER\\NLP_Projekt_Woche\\DeepLearningDudes_Music_Video\\.conda\\lib\\site-packages\\audiocraft\\modules\\transformer.py:546\u001b[0m, in \u001b[0;36mStreamingTransformerLayer._cross_attention_block\u001b[1;34m(self, src, cross_attention_src)\u001b[0m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attention \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;66;03m# queries are from src, keys and values from cross_attention_src.\u001b[39;00m\n\u001b[1;32m--> 546\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m    \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcross_attention_src\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcross_attention_src\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout_cross(x)\n",
      "File \u001b[1;32mc:\\Users\\980012754\\Documents\\TUM_8_SEMESTER\\NLP_Projekt_Woche\\DeepLearningDudes_Music_Video\\.conda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\980012754\\Documents\\TUM_8_SEMESTER\\NLP_Projekt_Woche\\DeepLearningDudes_Music_Video\\.conda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\980012754\\Documents\\TUM_8_SEMESTER\\NLP_Projekt_Woche\\DeepLearningDudes_Music_Video\\.conda\\lib\\site-packages\\audiocraft\\modules\\transformer.py:356\u001b[0m, in \u001b[0;36mStreamingMultiheadAttention.forward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m    354\u001b[0m q \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mlinear(query, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight[:dim], bias_q)\n\u001b[0;32m    355\u001b[0m \u001b[38;5;66;03m# todo: when streaming, we could actually save k, v and check the shape actually match.\u001b[39;00m\n\u001b[1;32m--> 356\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias_k\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    357\u001b[0m v \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mlinear(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight[\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m dim:], bias_v)\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqk_layer_norm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "modelMusic = musicModel(\"small\", 90)\n",
    "modelMusic.generateAudio(instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text-to-singing \n",
    "Reference model for voice generation: https://huggingface.co/coqui/XTTS-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTS.api import TTS\n",
    "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\", gpu=True)\n",
    "\n",
    "# generate speech by cloning a voice using default settings\n",
    "tts.tts_to_file(text=\"It took me quite a long time to develop a voice, and now that I have it I'm not going to be silent.\",\n",
    "                file_path=\"output.wav\",\n",
    "                speaker_wav=\"/path/to/target/speaker.wav\",\n",
    "                language=\"en\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
